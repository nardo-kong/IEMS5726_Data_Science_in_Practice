{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\86136\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# 1155202866\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2 as cv\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 2\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):      \n",
    "        self.X=torch.tensor(X.values, dtype=torch.float32)\n",
    "        self.y=torch.tensor(y.values, dtype=torch.float32)\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "   \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "def problem_2(df, Xlabel, ylabel, hidden=[3,3,3], test_size=0.3, batch_size=100, learning_rate=0.01, max_epochs=50000):\n",
    "    # write your logic here, model is the trained ANN model\n",
    "    model = []\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    f1score = 0\n",
    "    random_state = 4320  # default is 4320\n",
    "    module = []\n",
    "    \n",
    "    # YOUR CODE HERE: create the list of modules\n",
    "    n_features = len(Xlabel)\n",
    "    module.append(nn.Linear(n_features, hidden[0]))\n",
    "    module.append(nn.ReLU())\n",
    "    for i in range(len(hidden)-1):\n",
    "        module.append(nn.Linear(hidden[i], hidden[i+1]))\n",
    "        module.append(nn.ReLU())\n",
    "    \n",
    "    # the output layer is fixed to 1 neural and sigmoid\n",
    "    module.append(nn.Linear(hidden[-1],1))\n",
    "    module.append(nn.Sigmoid())\n",
    "    # create the nn model based on the list\n",
    "    model = nn.Sequential(*module)\n",
    "    \n",
    "    # split the dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[Xlabel], df[ylabel], test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # create the DataLoader for the training set\n",
    "    mytrain = MyDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(mytrain, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # use MSE loss function, and SGD optimizer\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # training loop\n",
    "    for epoch in range(max_epochs):\n",
    "        # you can uncomment the line below, to visualize the slow training process\n",
    "        # print(\"Debug: at epoch: \", epoch)\n",
    "        for data, labels in train_loader:\n",
    "            # YOUR CODE HERE: training loop\n",
    "            a = 0 # to prevent empty loop\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_function(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    \n",
    "    \n",
    "    # YOUR CODE HERE: follow the training set to create dataloader for testing\n",
    "    mytest = MyDataset(X_test, y_test)\n",
    "    test_loader = DataLoader(mytest, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # then, calculate the metrics\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for data, labels in test_loader:\n",
    "        output = model(data)\n",
    "        predicted_classes = (output > 0.5).float()\n",
    "        y_pred.extend(predicted_classes.view(-1).numpy())\n",
    "        y_true.extend(labels.view(-1).numpy())\n",
    "    \n",
    "    precision = metrics.precision_score(y_true, y_pred)\n",
    "    recall = metrics.recall_score(y_true, y_pred)\n",
    "    f1score = metrics.f1_score(y_true, y_pred)\n",
    "\n",
    "    return model, precision, recall, f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  Sequential(\n",
      "  (0): Linear(in_features=29, out_features=3, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=3, out_features=5, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=5, out_features=5, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=5, out_features=3, bias=True)\n",
      "  (7): ReLU()\n",
      "  (8): Linear(in_features=3, out_features=1, bias=True)\n",
      "  (9): Sigmoid()\n",
      ")\n",
      "precision:  0.49938741653916724\n",
      "recall:  1.0\n",
      "f1-score:  0.6661219255685572\n"
     ]
    }
   ],
   "source": [
    "# Testing: Problem 2\n",
    "df = pd.read_csv(\"creditcard_2023.csv\")\n",
    "Xlabel = [\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Amount\"]\n",
    "ylabel = [\"Class\"]\n",
    "model, p, r, f = problem_2(df, Xlabel, ylabel, hidden=[3,5,5,3], max_epochs=100)\n",
    "print(\"model: \", model)\n",
    "print(\"precision: \", p)\n",
    "print(\"recall: \", r)\n",
    "print(\"f1-score: \", f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 3\n",
    "def problem_3(image_filename):\n",
    "    # write your logic here, keypoint and descriptor are BRISK object\n",
    "    keypoint = 0\n",
    "    descriptor = 0\n",
    "\n",
    "    img = cv.imread(image_filename, cv.IMREAD_GRAYSCALE)\n",
    "    sift = cv.SIFT_create()\n",
    "    keypoint, descriptor = sift.detectAndCompute(img, None)\n",
    "    \n",
    "    return keypoint, descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158\n",
      "[[  0.  35. 145. ...   0.   0.  24.]\n",
      " [  1.  55.  20. ...   4.   0.   4.]\n",
      " [ 20.  77.   4. ...   0.  23.  16.]\n",
      " ...\n",
      " [ 52.   0.   0. ...   0.   0.   9.]\n",
      " [  9.   0.   5. ...   0.   0.   0.]\n",
      " [ 51.   2.   5. ...   0.   0.   2.]]\n",
      "(158, 128)\n"
     ]
    }
   ],
   "source": [
    "# Testing: Problem 3\n",
    "kp, des = problem_3(\"sample1.jpg\")\n",
    "print(kp)\n",
    "print(len(kp))\n",
    "print(des)\n",
    "print(des.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 4\n",
    "def problem_4(descriptor_list, k=5):\n",
    "    # write your logic here, visual_words are the cluster centroids\n",
    "    visual_words = 0\n",
    "    random_state = 5726\n",
    "    \n",
    "    descriptor_array = np.vstack(descriptor_list)\n",
    "    kmeans = KMeans(n_clusters=k, random_state=random_state).fit(descriptor_array)\n",
    "    visual_words = kmeans.cluster_centers_\n",
    "    \n",
    "    return visual_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 15.133332     6.2000027    4.9666653   17.53333     37.66667\n",
      "   40.06666     21.100002    19.633331    19.299995    12.933346\n",
      "   10.466669    20.433332    48.800007    44.66666     26.299995\n",
      "   24.133333    55.933334    19.466671    13.9000025    8.166664\n",
      "   10.299999    12.4         37.13333     71.26666     39.1\n",
      "    9.4333315   11.400001     8.066667     7.7333336   18.333336\n",
      "   32.          60.43333     14.099998     8.4333315   13.833329\n",
      "   42.86667     48.433334    26.3         17.766666    21.46667\n",
      "   36.36667     17.233332    15.166666    56.033333    79.93333\n",
      "   32.966663    10.066664     9.833332   128.63335     32.1\n",
      "    7.0333357    7.6000004   10.800001     8.900002    17.733335\n",
      "   62.766678    51.766666     9.466666     8.833333    13.266666\n",
      "   15.833336    36.266674    34.233337    44.73333     14.333334\n",
      "   26.83334     27.133331    51.1         37.8         20.733334\n",
      "   11.499996     8.566663    43.866665    13.133333    14.366667\n",
      "   40.76667     73.566666    41.83333     12.766663    20.566671\n",
      "  129.23332     55.666664    14.333332     7.199999     9.366665\n",
      "    7.0666676    6.833331    33.399998    58.299995    40.76667\n",
      "   31.066666    27.833336    20.5         12.833333     8.266665\n",
      "   11.299999    18.3         22.066662    22.3         29.800001\n",
      "   23.5         26.666664    19.133335     9.066664    31.333332\n",
      "   22.6         22.800001    27.93333     36.033337    29.6\n",
      "   18.2         20.199991    73.33333     51.933342    24.2\n",
      "   13.6          8.333334     8.566668    10.833336    24.066666\n",
      "   31.23333     45.033333    29.400002    16.1          9.000001\n",
      "    6.3333325    6.533332    11.166665  ]\n",
      " [ 35.769226    45.84616     26.192308    18.884613    26.807693\n",
      "   21.846153     4.115386     7.692307   108.49999     73.88463\n",
      "   19.038462    12.923075     7.9615374    3.5769224    3.5769196\n",
      "   26.807692    61.46154     18.923082     8.269234     9.423076\n",
      "    5.615385     6.76923      9.384614    34.923077     9.076925\n",
      "    7.615383    13.269233     9.576923     3.6923075    8.692307\n",
      "    8.230769    12.8076935   34.692307    25.653845    25.076921\n",
      "   35.42308     49.07693     43.846153    11.615387    11.500001\n",
      "  148.3077      65.96154     12.730769     7.8461533   10.384609\n",
      "    6.038459     4.999997    33.076923   100.80769     17.8077\n",
      "   10.961538    11.076924    12.884617    11.19231     13.192308\n",
      "   31.307693    10.884617     6.23077     21.538464    12.884615\n",
      "    7.653846     9.961536    14.153845    12.807688    34.269234\n",
      "    5.5384617    6.4230795   12.5         53.192307    53.346157\n",
      "   26.923075    31.30769    144.50002     23.538462     3.653843\n",
      "    2.2307682   13.730768    14.384611    16.230766    66.53847\n",
      "  109.57692     19.961535     9.384612     7.500001    13.230768\n",
      "   10.269232     7.615383    23.346151     8.30769      3.846157\n",
      "    9.961537     9.384615    15.423077    12.6923065   13.5\n",
      "   11.961536    35.153854     7.192307     7.26923     13.076921\n",
      "   42.3077      28.923077    21.307693    32.11538    115.23076\n",
      "   14.23077      4.0384626    3.4615355   13.038463    13.884611\n",
      "   17.692308    69.5         68.65384     17.19231      7.000002\n",
      "    4.230769     4.3846154    2.5384607   10.076923    30.423077\n",
      "    7.115385     3.653839     4.346154     9.5          7.8846154\n",
      "   11.423077     9.884614     7.1538486 ]\n",
      " [ 17.483871    11.4838705   16.580647    18.48387     16.387096\n",
      "   22.903227    21.483871    17.83871     97.74193     60.516132\n",
      "   14.19355      8.612906     7.87097     13.193548     9.129032\n",
      "   23.870968   131.45163     77.3871       2.4193583    2.7096777\n",
      "    1.9677439    1.2580643    5.806451    23.032257    41.709675\n",
      "   14.258061     2.6451626    3.483871     4.903226     2.6451635\n",
      "    6.6451616   20.741938    19.548386     7.1935453    9.322575\n",
      "   14.419359    12.258062    30.870968    29.741938    24.290323\n",
      "  100.16129     32.741936     7.6451645   20.483871    24.225807\n",
      "   22.387094    19.193546    23.612898   148.48386     65.225815\n",
      "    3.258071     4.903224     3.3548365    1.9677448    4.258066\n",
      "   22.12904     69.          17.129032     3.5483885    3.6774197\n",
      "    4.903228     4.4838753    5.9032288   15.709674    14.709678\n",
      "    8.387098    15.258064    20.774193    16.548391    25.322584\n",
      "   23.999998    23.709673    85.129036     9.322582    11.16129\n",
      "   26.45161     31.          23.064514    18.225803    44.51613\n",
      "  147.16127     13.354834     4.806449     4.903228     2.4516125\n",
      "    1.9354849    3.6128998   69.93548     68.870964    12.774198\n",
      "    2.1935463    1.7419386    1.9354849    5.5161266    6.258065\n",
      "   13.806452    10.612904     4.3870983   16.354836    25.741934\n",
      "   14.129035    14.161285    19.35484     21.548386    77.935486\n",
      "    5.838704     4.5806475   14.709677    18.54839      9.2903185\n",
      "   17.645164    71.774185   133.90326      4.7742043    1.2580624\n",
      "    2.548387     1.8387103    0.32257938   2.290326    86.77417\n",
      "   41.838707     9.677412     3.5806484    3.7741938    1.4838696\n",
      "    0.8387079    2.3548393   10.290321  ]\n",
      " [ 10.6         23.033333    34.333336    28.066666    11.299997\n",
      "    7.0666647   10.966668    10.666666    14.166668    39.266666\n",
      "   55.5         36.36667     19.733334     8.566668     5.7333307\n",
      "    9.700005    47.666664    48.600006    27.300003    21.93333\n",
      "   17.433334     4.766666     3.0999985   19.133331    37.166664\n",
      "   20.5          6.166668     5.5999994   11.466667     5.8999996\n",
      "    9.033333    40.100002     5.699995    18.533333    45.3\n",
      "   52.6         30.466663    15.633332    20.5         10.900001\n",
      "   22.3         41.233334    78.16669     88.73334     45.66666\n",
      "   19.866667    12.366663     7.100004   128.20001     79.20001\n",
      "   42.499996    17.533335     5.499999     3.300003     4.466667\n",
      "   36.266666    73.86667     14.933333     3.5333343    4.5666666\n",
      "    8.133333    11.066666    15.933332    44.166664     7.699996\n",
      "    6.7666664   18.900002    31.466665    38.8         36.766666\n",
      "   39.466667    24.633333    30.766682     7.9000015   15.166666\n",
      "   31.066666    50.033333    71.1         67.3         39.033333\n",
      "  130.79999     38.533337     9.666663     4.466666     6.5666656\n",
      "   15.700002    34.43333     71.799995    78.566666    42.233337\n",
      "   19.2         15.233335     7.566665     3.366664     6.100001\n",
      "   17.8         10.266665    10.266666     7.7999988   18.099998\n",
      "   30.733337    26.299997    30.200003    22.          23.433323\n",
      "   13.600001    10.366667    13.166666    39.833336    32.999996\n",
      "   40.800003    35.06667     61.36666     29.133333    16.533335\n",
      "   11.4         16.833332    19.333332    27.333334    40.933334\n",
      "   45.666664    38.23333     22.800003    15.133333     7.5333333\n",
      "    6.0666656    5.333332    18.533333  ]\n",
      " [ 11.878049    18.95122     43.658535    37.14634     28.048777\n",
      "   13.756098    11.390245    13.          34.2439      35.02439\n",
      "   39.585365    27.292683    17.19512     10.317074    22.756094\n",
      "   36.195126    31.097569    32.53659     30.414635    19.512196\n",
      "   15.439026    19.82927     28.463413    37.926826    33.878048\n",
      "   31.87805     20.243904    11.219512     6.7317066   12.219512\n",
      "   18.219513    28.317074    32.19512     23.682922    34.146336\n",
      "   38.536587    48.58537     25.512196     9.780491    10.829269\n",
      "  115.804886    37.07317     19.292683    13.463415    12.951216\n",
      "   11.12195     32.46341     79.780495    34.146324    15.60977\n",
      "   12.658537    20.902435    35.14634     53.731705    57.82926\n",
      "   49.41464     47.85366     30.414642    13.902442    13.853659\n",
      "   18.536587    19.707315    16.          26.439024    38.024387\n",
      "   11.95122      8.804881    18.90244     45.31707     48.975613\n",
      "   33.951218    19.585365   116.87805     66.26829     21.951218\n",
      "   11.0487795   13.414635    15.731705    22.12195     38.682926\n",
      "   43.121956    36.707317    36.80488     40.951225    37.39025\n",
      "   29.756092    21.902435    19.609755    41.146336    24.146341\n",
      "   10.975611    12.195123    23.243904    25.487806    22.170727\n",
      "   27.048775    19.170732    17.731707    10.097561    10.829268\n",
      "   29.853659    37.780483    35.02439     19.414633    50.341465\n",
      "   43.707314    20.121952    10.926828    16.80488     27.853655\n",
      "   33.560974    28.14634     37.90245     43.609764    31.536583\n",
      "   17.219513    11.073172    14.951219    24.317076    26.90244\n",
      "   29.829268    23.268293    14.902439    13.829268    17.756096\n",
      "   17.41463     14.731709    22.804878  ]]\n",
      "(5, 128)\n"
     ]
    }
   ],
   "source": [
    "# Testing: Problem 4\n",
    "kp, des = problem_3(\"sample1.jpg\")\n",
    "visual_words = problem_4(des)\n",
    "print(visual_words)\n",
    "print(visual_words.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 5\n",
    "# Takes 2 parameters. The first one is a dictionary that holds the descriptors that are separated class by class \n",
    "# And the second parameter is an array that holds the central points (visual words) of the k means clustering\n",
    "# Returns a dictionary that holds the histograms for each images that are separated class by class. \n",
    "def image_class(all_bovw, centers):\n",
    "    dict_feature = {}\n",
    "    for key,value in all_bovw.items():\n",
    "        category = []\n",
    "        for img in value:\n",
    "            histogram = np.zeros(len(centers))\n",
    "            for each_feature in img:\n",
    "                ind = find_index(each_feature, centers)\n",
    "                histogram[ind] += 1\n",
    "            category.append(histogram)\n",
    "        dict_feature[key] = category\n",
    "    return dict_feature\n",
    "\n",
    "def find_index(each_feature, centers):\n",
    "    best = 0\n",
    "    dist = np.linalg.norm(each_feature-centers[0])\n",
    "    for k in range(len(centers)):\n",
    "        if np.linalg.norm(each_feature-centers[k]) < dist:\n",
    "            best = k\n",
    "            dist = np.linalg.norm(each_feature-centers[k])\n",
    "    return best\n",
    "\n",
    "def problem_5(list_of_image, k=5):\n",
    "    # write your logic here, visual_bag_of_words is a dictionary\n",
    "    sift_vectors = {}\n",
    "    descriptor_list = []\n",
    "    visual_bag_of_words = {}\n",
    "\n",
    "    # YOUR CODE HERE:\n",
    "    # reuse problem 3 and collect the list of all descriptors\n",
    "    for img in list_of_image:\n",
    "        kp, des = problem_3(img)\n",
    "        descriptor_list.append(des)\n",
    "        sift_vectors[img] = des\n",
    "\n",
    "    # YOUR CODE HERE:\n",
    "    # reuse problem 4 and obtain the visual words\n",
    "    visual_words = problem_4(descriptor_list, k)\n",
    "\n",
    "    # YOUR CODE HERE:\n",
    "    # based on the visual words and cluster centers\n",
    "    # construct the visual bow (dict)\n",
    "    for img in list_of_image:\n",
    "        visual_bag_of_words[img] = image_class({img: [sift_vectors[img]]}, visual_words)[img]\n",
    "\n",
    "    return visual_bag_of_words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sample1.jpg': [array([26.,  5., 31., 18.,  9., 24.,  5.,  5., 33.,  2.])], 'sample2.jpg': [array([ 10.,  27., 130.,  22.,  55.,  36.,  20.,  44.,  55.,  45.])], 'sample3.jpg': [array([37., 15., 47., 39., 75., 61., 42., 31., 64., 25.])], 'sample4.jpg': [array([11., 20., 27., 11.,  7., 63.,  4., 13., 43.,  7.])], 'sample5.jpg': [array([176., 245., 185., 256., 311.,  91., 321., 353., 105., 205.])]}\n"
     ]
    }
   ],
   "source": [
    "# Testing: Problem 5\n",
    "list_of_image = [\"sample1.jpg\", \"sample2.jpg\", \"sample3.jpg\", \"sample4.jpg\", \"sample5.jpg\"]\n",
    "vbow = problem_5(list_of_image, 10)\n",
    "print(vbow)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 6\n",
    "from sklearn.model_selection import KFold\n",
    "def problem_6(df_X, df_y, kfold=10, alpha=1.0):\n",
    "    # write your logic here, model is the trained ridge model\n",
    "    model = 0\n",
    "    rmse = 0\n",
    "    random_state = 4320  # default is 4320\n",
    "    random.seed(random_state) # may be useful\n",
    "\n",
    "    model = Ridge(alpha=alpha)\n",
    "    kf = KFold(n_splits=kfold, random_state=random_state, shuffle=True)\n",
    "    \n",
    "    squared_errors = []\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    for train_index, test_index in kf.split(df_X):\n",
    "        X_train, X_test = df_X.iloc[train_index], df_X.iloc[test_index]\n",
    "        y_train, y_test = df_y.iloc[train_index], df_y.iloc[test_index]\n",
    "        \n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        squared_errors.append(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    rmse = np.sqrt(np.mean(squared_errors))\n",
    "\n",
    "    model.fit(df_X, df_y)\n",
    "    \n",
    "    \n",
    "    return model, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  Ridge()\n",
      "cv rmse:  101230.77274562986\n"
     ]
    }
   ],
   "source": [
    "# Testing: Problem 6\n",
    "df = pd.read_csv('USA_Housing.csv')\n",
    "df_X = df[['Avg. Area Income', 'Avg. Area House Age', 'Avg. Area Number of Rooms', 'Avg. Area Number of Bedrooms', 'Area Population']]\n",
    "df_X = pd.DataFrame(StandardScaler().fit_transform(df_X.values))\n",
    "df_y = df['Price']\n",
    "model, rmse = problem_6(df_X, df_y, kfold=10)\n",
    "print(\"model: \", model)\n",
    "print(\"cv rmse: \", rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
