{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\86136\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# 1155202866\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Problem 2\n",
    "def problem_2(df, k=5, t=0.2):\n",
    "    list = []\n",
    "    train, test = train_test_split(df, test_size=t)\n",
    "    list_size = len(train) // k\n",
    "    reminder = len(train) % k\n",
    "    for i in range(k):\n",
    "        if i < reminder:\n",
    "            list.append(train[i * (list_size + 1):(i + 1) * (list_size + 1)])\n",
    "        else:\n",
    "            list.append(train[i * list_size + reminder:(i + 1) * list_size + reminder])\n",
    "    return list, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment:  (166, 6)\n",
      "Segment:  (166, 6)\n",
      "Segment:  (165, 6)\n",
      "Segment:  (165, 6)\n",
      "Segment:  (165, 6)\n",
      "Test:  (207, 6)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"mlb_players.csv\")\n",
    "list, test = problem_2(df, k=5, t=0.2)\n",
    "for item in list:\n",
    "    print(\"Segment: \", item.shape)\n",
    "\n",
    "print(\"Test: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_11280/2559028096.py, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\86136\\AppData\\Local\\Temp/ipykernel_11280/2559028096.py\"\u001b[1;36m, line \u001b[1;32m19\u001b[0m\n\u001b[1;33m    if (num_channels 1 and 1 == 2):\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Problem 3\n",
    "import torchaudio\n",
    "from torchaudio import transforms\n",
    "import torch\n",
    "def problem_3(audio_object, new_sr, max_mask_pct, n_freq_masks,n_time_masks):\n",
    "    sig,sr = audio_object\n",
    "    top_db = 80\n",
    "    n_mels = 64\n",
    "    n_fft = 1024\n",
    "    hop_len = None\n",
    "    aug_spec = 0 # it should be the augmented mel spectrogram\n",
    "    # write your logic here\n",
    "\n",
    "    # Standardize Sampling Rate\n",
    "    if (sr != new_sr):\n",
    "        num_channels = sig.shape[0]\n",
    "        # Resample first channel\n",
    "        resig = torchaudio.transforms.Resample(sr, new_sr)(sig[:1,:])\n",
    "        if (num_channels > 1 and 1 == 2):\n",
    "            # Resample the second channel and merge both channels\n",
    "            retwo = torchaudio.transforms.Resample(sr, new_sr)(sig[1:,:])\n",
    "            resig = torch.cat([resig, retwo])\n",
    "        sig = resig\n",
    "        sr = new_sr\n",
    "    \n",
    "    # Mel Spectrogram\n",
    "    # spec has shape [channel, n_mels, time], where channel is mono, stereo etc\n",
    "    spec = transforms.MelSpectrogram(sr, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n",
    "    # Convert to decibels\n",
    "    spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
    "    \n",
    "    # Time and Frequency Masking\n",
    "    _, n_mels, n_steps = spec.shape\n",
    "    mask_value = spec.mean()\n",
    "    aug_spec = spec\n",
    "    freq_mask_param = max_mask_pct * n_mels\n",
    "    for _ in range(n_freq_masks):\n",
    "        aug_spec = transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value)\n",
    "    time_mask_param = max_mask_pct * n_steps\n",
    "    for _ in range(n_time_masks):\n",
    "        aug_spec = transforms.TimeMasking(time_mask_param)(aug_spec, mask_value)\n",
    "    return aug_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-15.7986, -26.2079,  -2.5823,  ..., -17.5216, -25.1742,  -6.4820],\n",
      "         [-14.9909, -26.3129,  -2.5823,  ..., -15.8489, -21.4932,  -5.8881],\n",
      "         [-15.5878, -27.2463,  -2.5823,  ..., -23.3073, -22.9119,  -4.6153],\n",
      "         ...,\n",
      "         [ -1.3068,  -7.9676,  -2.5823,  ...,  -9.0166,  -2.7825,  -0.4647],\n",
      "         [ -5.3689, -13.3607,  -2.5823,  ...,   3.2213,   8.2229,   2.9625],\n",
      "         [ -5.3918, -14.7075,  -2.5823,  ...,   8.5705,  18.2588,   9.0654]]])\n",
      "torch.Size([1, 64, 21])\n"
     ]
    }
   ],
   "source": [
    "audio_file = \"greensleeves.mp3\"\n",
    "sig, sr = torchaudio.load(audio_file)\n",
    "# first 10 second\n",
    "sig = sig[:,:10*sr]\n",
    "new_sr, max_mask_pct, n_freq_masks, n_time_masks = 1024, 0.1, 1, 1\n",
    "aug_spec = problem_3((sig,sr), new_sr, max_mask_pct, n_freq_masks,n_time_masks)\n",
    "print(aug_spec)\n",
    "print(aug_spec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 4\n",
    "def problem_4(input_mat):\n",
    "    output_mat = np.array([0])\n",
    "    # write your logic here\n",
    "    for i in range(input_mat.shape[0]):\n",
    "        for j in range(input_mat.shape[1]):\n",
    "            output_mat = np.append(output_mat, input_mat[i][j])\n",
    "        \n",
    "    return output_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input [[1 2 3]\n",
      " [4 5 6]]\n",
      "Output [0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "input_mat = np.array([[1,2,3],[4,5,6]])\n",
    "output_mat = problem_4(input_mat)\n",
    "print(\"Input\", input_mat)\n",
    "print(\"Output\", output_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 5\n",
    "import re\n",
    "def problem_5(df_input):\n",
    "    df_output = df_input\n",
    "    # write your logic here\n",
    "    for i in range(df_output.shape[0]):\n",
    "        error = False\n",
    "        number = df_output.iloc[i,0]\n",
    "        if '1' <= number[0] <= '9':\n",
    "            if len(number) == 9:\n",
    "                if number[4] == '-':\n",
    "                    number = number.replace('-', '')\n",
    "            if len(number) == 8:\n",
    "                for k in range(8):\n",
    "                    if number[k] < '0' or number[k] > '9':\n",
    "                        error = True\n",
    "            else:\n",
    "                error = True\n",
    "        else:\n",
    "            error = True\n",
    "        if error == False:\n",
    "            df_output.iloc[i,0] = number\n",
    "        else:\n",
    "            df_output.iloc[i,0] = 'ERROR'\n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      phone\n",
      "0  12345678\n",
      "1     ERROR\n",
      "2     ERROR\n",
      "3  88884444\n",
      "4  98983434\n",
      "(5, 1)\n"
     ]
    }
   ],
   "source": [
    "list_of_number = [\"1234-5678\", \"0123-4567\", \"1234567\", \"8888-4444\",\"98983434\"]\n",
    "dict = {\"phone\":list_of_number}\n",
    "df = pd.DataFrame(dict)\n",
    "df_result = problem_5(df)\n",
    "print(df_result)\n",
    "print(df_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 6\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def problem_6(df_input, label, k1=10, k2=10):\n",
    "    df_output = df_input\n",
    "    # write your logic here\n",
    "\n",
    "    X = df_output.drop(label, axis=1)\n",
    "    y = df_output[label]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    pca = PCA(n_components=k1)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    df_pca = pd.DataFrame(data = X_pca, columns = [i for i in range(k1)])\n",
    "\n",
    "    lda = LDA(n_components=k2)\n",
    "    X_lda = lda.fit_transform(X_scaled, y)\n",
    "    df_lda = pd.DataFrame(data = X_lda, columns = [i+k1 for i in range(k2)])\n",
    "\n",
    "    df_output = pd.concat([df_pca, df_lda], axis=1)\n",
    "    \n",
    "    \n",
    "    return df_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3\n",
      "0   -2.264542  0.505704 -0.121943  8.084953\n",
      "1   -2.086426 -0.655405 -0.227251  7.147163\n",
      "2   -2.367950 -0.318477  0.051480  7.511378\n",
      "3   -2.304197 -0.575368  0.098860  6.837676\n",
      "4   -2.388777  0.674767  0.021428  8.157814\n",
      "..        ...       ...       ...       ...\n",
      "145  1.870522  0.382822  0.254532 -5.674013\n",
      "146  1.558492 -0.905314 -0.025382 -5.197129\n",
      "147  1.520845  0.266795  0.179277 -4.981712\n",
      "148  1.376391  1.016362  0.931405 -5.901486\n",
      "149  0.959299 -0.022284  0.528794 -4.684009\n",
      "\n",
      "[150 rows x 4 columns]\n",
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length','petal-width', 'Class']\n",
    "dataset = pd.read_csv(url, names=names)\n",
    "df_feature = problem_6(dataset, 'Class', 3, 1)\n",
    "print(df_feature)\n",
    "print(df_feature.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
